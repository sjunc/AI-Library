{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjunc/AI-Library/blob/main/class/W12_Attention_Mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-JvBZLHS6u2",
        "outputId": "24ef8b6e-1ec4-40d5-c32b-35174676908e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go\\t가\\tccby 20 france attribution tatoebaorg 2877272 cm  8363271 eunhee', 'hi\\t안녕\\tccby 20 france attribution tatoebaorg 538123 cm  8355888 eunhee', 'run\\t뛰어\\tccby 20 france attribution tatoebaorg 906328 papabear  8355891 eunhee', 'run\\t뛰어\\tccby 20 france attribution tatoebaorg 4008918 jsakuragi  8363273 eunhee', 'who\\t누구\\tccby 20 france attribution tatoebaorg 2083030 ck  6820074 yesjustryan']\n"
          ]
        }
      ],
      "source": [
        "# 데이터 확인해보기\n",
        "\n",
        "import string\n",
        "\n",
        "I = [] # 전처리된 문장을 저장할 리스트\n",
        "\n",
        "# 한글 텍스트 파일을 읽기 위해 utf-8 인코딩으로 읽어옴\n",
        "\n",
        "with open(\n",
        "    \"kor.txt\",\n",
        "    'r', encoding = \"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    for line in lines:\n",
        "      # 특수 문자를 지우고 모든 글자를 소문자로 변경\n",
        "      txt = \"\".join(v for v in line if v not in string.punctuation).lower()\n",
        "      I.append(txt)\n",
        "\n",
        "print(I[:5]) # 정제된 문장 중 앞부분 5개 출력 (예시 확인용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LparkN60T5ZQ"
      },
      "outputs": [],
      "source": [
        "# BOW (bag of word) 생성 함수 정의\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "def get_BOW(corpus):    # 문장들로부터 BOW를 만드는 함수\n",
        "  BOW = {\"<SOS>\": 0, \"<EOS>\": 1}  # <SOS> 토큰과 <EOS> 토큰을 추가\n",
        "# <SOS> 토큰: Start of Seqeunce, 문장의 시작을 알리는 토큰 - 디코딩을 시작하라는 신호\n",
        "# <EOS> 토큰: End of Sequence, 문장의 끝을 알리는 토큰 - 디코딩을 끝내라는 신호\n",
        "  #문장 내 단어들을 이용해 BOW를 생성\n",
        "  for line in corpus:   # 각 문장을 순회하면서\n",
        "      for word in line.split():     # 각 문장을 단어 단위로 나눈 후\n",
        "          if word not in BOW.keys():    # BOW에 없는 단어라면 새로운 인덱스로 추가\n",
        "              BOW[word] = len(BOW.keys())\n",
        "\n",
        "  return BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2wuNaXRVS2N"
      },
      "outputs": [],
      "source": [
        "# 학습에 사용할 데이터셋 정의\n",
        "\n",
        "class Eng2Kor(Dataset):   # 학습에 이용할 데이터셋\n",
        "  def __init__(\n",
        "      self,\n",
        "      pth2txt = \\\n",
        "      \"kor.txt\"):\n",
        "      self.eng_corpus = [] # 영어 문장이 들어가는 변수\n",
        "      self.kor_corpus = [] # 한글 문장이 들어가는 변수\n",
        "\n",
        "      # 텍스트 파일을 읽어서 영어 문장과 한글 문장을 저장\n",
        "      with open(pth2txt, 'r', encoding = \"utf-8\") as f:\n",
        "        lines = f.read().split(\"\\n\")\n",
        "        for line in lines:\n",
        "          # 빈 줄 건너뛰기\n",
        "           if not line.strip():\n",
        "              continue\n",
        "\n",
        "           parts = line.split(\"\\t\") # 탭(\\t)으로 영어/한글 문장 분리\n",
        "           if len(parts) >= 2:  # 영어, 한글 문장이 모두 있는 경우만 처리\n",
        "              # 영어 문장에서 특수 문자 제거 및 소문자 변환\n",
        "              engtxt = \"\".join(\n",
        "                  v for v in parts[0] if v not in string.punctuation\n",
        "              ).lower()\n",
        "\n",
        "              # 한국어 문장에서 특수 문자 제거\n",
        "              kortxt = \"\".join(\n",
        "                  v for v in parts[1] if v not in string.punctuation\n",
        "              )\n",
        "\n",
        "              # 너무 긴 문장은 제외 (10단어 이하만 사용)\n",
        "              if len(engtxt.split()) <= 10 and len(kortxt.split()) <= 10:\n",
        "                  self.eng_corpus.append(engtxt)\n",
        "                  self.kor_corpus.append(kortxt)\n",
        "\n",
        "      self.engBOW = get_BOW(self.eng_corpus)    # 영어 BOW\n",
        "      self.korBOW = get_BOW(self.kor_corpus)    # 한글 BOW\n",
        "\n",
        " # 문장을 단어 리스트로 나눈 뒤 <EOS> 토큰 추가\n",
        "  def gen_seq(self, line):\n",
        "      seq = line.split()\n",
        "      seq.append(\"<EOS>\")\n",
        "\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.eng_corpus)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n",
        "    data = np.array([\n",
        "        self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])])\n",
        "\n",
        "    label = np.array([\n",
        "        self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])])\n",
        "\n",
        "    return data, label\n",
        "\n",
        "  # 샘플 데이터를 출력하는 함수 추가\n",
        "  def print_samples(self, num_samples = 5):\n",
        "    \"\"\"\n",
        "    데이터셋에서 num_samples 개수만큼 샘플을 출력합니다.\n",
        "    \"\"\"\n",
        "    print(f\"데이터셋 크기: {len(self.eng_corpus)} 쌍의 문장\")\n",
        "    print(\"\\n샘플 데이터:\")\n",
        "\n",
        "    # 데이터 셋 크기보다 많은 샘들을 요청한 경우 조정\n",
        "    num_samples = min(num_samples, len(self.eng_corpus))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        print(f\"샘플 {i+1} :\")\n",
        "        print(f\" 영어: {self.eng_corpus[i]}\")\n",
        "        print(f\" 한글: {self.kor_corpus[i]}\")\n",
        "\n",
        "        # 숫자 표현도 확인\n",
        "\n",
        "        eng_indices = [self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])]\n",
        "        kor_indices = [self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])]\n",
        "\n",
        "        print(f\" 영어 인덱스: {eng_indices}\")\n",
        "        print(f\" 한국어 인덱스: {kor_indices}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jJPETleb9Kx",
        "outputId": "041c7900-a968-4ce8-c9e2-740130fef80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋 크기: 5701 쌍의 문장\n",
            "\n",
            "샘플 데이터:\n",
            "샘플 1 :\n",
            " 영어: go\n",
            " 한글: 가\n",
            " 영어 인덱스: [2, 1]\n",
            " 한국어 인덱스: [2, 1]\n",
            "\n",
            "샘플 2 :\n",
            " 영어: hi\n",
            " 한글: 안녕\n",
            " 영어 인덱스: [3, 1]\n",
            " 한국어 인덱스: [3, 1]\n",
            "\n",
            "샘플 3 :\n",
            " 영어: run\n",
            " 한글: 뛰어\n",
            " 영어 인덱스: [4, 1]\n",
            " 한국어 인덱스: [4, 1]\n",
            "\n",
            "샘플 4 :\n",
            " 영어: run\n",
            " 한글: 뛰어\n",
            " 영어 인덱스: [4, 1]\n",
            " 한국어 인덱스: [4, 1]\n",
            "\n",
            "샘플 5 :\n",
            " 영어: who\n",
            " 한글: 누구\n",
            " 영어 인덱스: [5, 1]\n",
            " 한국어 인덱스: [5, 1]\n",
            "\n",
            "샘플 6 :\n",
            " 영어: wow\n",
            " 한글: 우와\n",
            " 영어 인덱스: [6, 1]\n",
            " 한국어 인덱스: [6, 1]\n",
            "\n",
            "샘플 7 :\n",
            " 영어: duck\n",
            " 한글: 숙여\n",
            " 영어 인덱스: [7, 1]\n",
            " 한국어 인덱스: [7, 1]\n",
            "\n",
            "샘플 8 :\n",
            " 영어: fire\n",
            " 한글: 쏴\n",
            " 영어 인덱스: [8, 1]\n",
            " 한국어 인덱스: [8, 1]\n",
            "\n",
            "샘플 9 :\n",
            " 영어: help\n",
            " 한글: 도와줘\n",
            " 영어 인덱스: [9, 1]\n",
            " 한국어 인덱스: [9, 1]\n",
            "\n",
            "샘플 10 :\n",
            " 영어: hide\n",
            " 한글: 숨어\n",
            " 영어 인덱스: [10, 1]\n",
            " 한국어 인덱스: [10, 1]\n",
            "\n",
            "영어 어휘 크기: 3048\n",
            "한국어 어휘 크기: 7466\n",
            "\n",
            "영어 단어 인덱스 예시:\n",
            "  'go': 2\n",
            "  'hello': 15\n",
            "  'thank': 180\n",
            "  '<SOS>': 0\n",
            "  '<EOS>': 1\n",
            "\n",
            "한국어 단어 인덱스 예시:\n",
            "  '가': 2\n",
            "  '안녕': 3\n",
            "  '감사합니다': 6442\n",
            "  '<SOS>': 0\n",
            "  '<EOS>': 1\n"
          ]
        }
      ],
      "source": [
        "# 샘플 데이터 출력해보기\n",
        "\n",
        "# 데이터셋 생성\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 샘플 데이터 10개 출력\n",
        "dataset.print_samples(10)\n",
        "\n",
        "# BOW 사전 크기 확인\n",
        "print(f\"영어 어휘 크기: {len(dataset.engBOW)}\")\n",
        "print(f\"한국어 어휘 크기: {len(dataset.korBOW)}\")\n",
        "\n",
        "# 몇 가지 단어의 인덱스 확인\n",
        "print(\"\\n영어 단어 인덱스 예시:\")\n",
        "for word in [\"go\", \"hello\", \"thank\", \"<SOS>\", \"<EOS>\"]:\n",
        "    if word in dataset.engBOW:\n",
        "        print(f\"  '{word}': {dataset.engBOW[word]}\")\n",
        "    else:\n",
        "        print(f\"  '{word}':  사전에 없습니다.\")\n",
        "\n",
        "print(\"\\n한국어 단어 인덱스 예시:\")\n",
        "for word in [\"가\", \"안녕\", \"감사합니다\", \"<SOS>\", \"<EOS>\"]:\n",
        "    if word in dataset.korBOW:\n",
        "        print(f\"  '{word}': {dataset.korBOW[word]}\")\n",
        "    else:\n",
        "        print(f\"  '{word}':  사전에 없습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CybewxyDdiup"
      },
      "outputs": [],
      "source": [
        "# 학습에 사용할 데이터 로더 정의\n",
        "\n",
        "def loader(dataset):    # 데이터셋의 문장을 한문장씩 불러오기 위한 함수\n",
        "    for i in range(len(dataset)):\n",
        "        data, label = dataset[i]\n",
        "\n",
        "        # numpy array -> torch tensor로 변환 후 반환\n",
        "        # 매 반복마다 하나의 (입력, 정답) 쌍을 yield (제네레이터 형태)\n",
        "        yield torch.tensor(data), torch.tensor(label)   #  yield 키워드를 사용하면 제너레이터를 반환한다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt1I-hZQfR-X"
      },
      "outputs": [],
      "source": [
        "# 인코더 정의\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    # 단어 인덱스를 임베딩 벡터로 변환 (input_size: 단어 수, hidden_size: 벡터 차원)\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    # GRU 정의 (입력과 은닉 상태의 차원이 같음)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, x, h):\n",
        "    # 배치 차원과 시계열 차원 추가 (모양 맞춰주기 용도)\n",
        "    x = self.embedding(x).view(1, 1, -1)\n",
        "    # GRU에 입력과 이전 hidden state를 넣고, 출력과 새로운 hidden state를 반환\n",
        "    output, hidden = self.gru(x, h)\n",
        "    return output, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzYLfkB2goFy"
      },
      "outputs": [],
      "source": [
        "# 디코더 정의\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p = 0.1, max_length = 11):\n",
        "      super(Decoder, self).__init__()\n",
        "\n",
        "      # 출력 단어 인덱스를 hidden_size 차원의 임베딩 벡터로 변환\n",
        "      self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "      # 어텐션 가중치를 계산하기 위한 MLP 층\n",
        "      self.attention = nn.Linear(hidden_size *2, max_length)\n",
        "\n",
        "      # context vector + 임베딩을 결합한 후 특징 추출하는 MLP\n",
        "      self.context = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "      # 과적합을 피하기 위한 드롭아웃 층\n",
        "      self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "      # GRU 계층 (입력: context 특징, 은닉 상태)\n",
        "      self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "      # 최종 출력층: hidden -> 단어 개수 크기의 벡터 (단어 분류용)\n",
        "      self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "      # 활성화 함수들\n",
        "      self.relu = nn.ReLU()\n",
        "      self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, x, h, encoder_outputs):\n",
        "      # 입력 단어 인덱스를 임베딩하고 (1, 1, hidden_size) 형태로 변형\n",
        "      x = self.embedding(x).view(1, 1, -1)\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # 어텐션 가중치 계산:\n",
        "      # 현재 입력(임베딩)과 이전 hidden state를 이어붙여 attention score 계산\n",
        "      attn_weights = self.softmax(\n",
        "        self.attention(torch.cat((x[0], h[0]), -1)) # 결과 shape: (1, max_length)\n",
        "      )\n",
        "\n",
        "      # 인코더의 출력 전체에 어텐션 가중치를 곱해 context vector 생성\n",
        "      attn_applied = torch.bmm(\n",
        "          attn_weights.unsqueeze(0),\n",
        "          encoder_outputs.unsqueeze(0)\n",
        "      )\n",
        "      # 인코더 각 시점의 중요도와 밀집 표현을 합쳐 MLP 층으로 특징 추출\n",
        "      output = torch.cat((x[0], attn_applied[0]), 1)\n",
        "      output = self.context(output).unsqueeze(0)\n",
        "      output = self.relu(output)\n",
        "\n",
        "      # GRU로 다음 hidden state 계산\n",
        "      output, hidden = self.gru(output, h)\n",
        "\n",
        "      # hidden -> vocabulary size로 변환 (각 단어의 확률 분포)\n",
        "      output = self.out(output[0])\n",
        "\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJLibQfgh1al"
      },
      "outputs": [],
      "source": [
        "# 학습에 필요한 요소 정의\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# 학습에 사용할 데이터셋 정의 (전처리 + BOW 사전 포함)\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p = 0.1).to(device)\n",
        "\n",
        "# 인코더 디코더 학습을 위한 최적화 정의\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr = 0.001)\n",
        "decoder_optimizer = Adam(decoder.parameters(), lr = 0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "DR6bgvxNkq2t",
        "outputId": "0c0ad67a-1095-4882-dddf-a94f37cd46db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5701 [00:00<?, ?it/s]C:\\Users\\109-1\\AppData\\Local\\Temp\\ipykernel_17824\\3275831005.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype = torch.long).to(device)\n",
            "C:\\Users\\109-1\\AppData\\Local\\Temp\\ipykernel_17824\\3275831005.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(label, dtype = torch.long).to(device)\n",
            "C:\\Users\\109-1\\AppData\\Local\\Temp\\ipykernel_17824\\3275831005.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label[di], dtype = torch.long).to(device)\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 303.84it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.65it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.93it/s]\n",
            "100%|██████████| 5701/5701 [00:21<00:00, 261.50it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 189.02it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 188.00it/s]\n",
            "100%|██████████| 5701/5701 [00:29<00:00, 191.51it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 189.04it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 188.37it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 187.77it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 186.79it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 186.74it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 187.21it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 186.76it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 187.84it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 187.94it/s]\n",
            "100%|██████████| 5701/5701 [00:29<00:00, 190.74it/s]\n",
            "100%|██████████| 5701/5701 [00:29<00:00, 190.32it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 188.18it/s]\n",
            "100%|██████████| 5701/5701 [00:29<00:00, 193.86it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 189.58it/s]\n",
            "100%|██████████| 5701/5701 [00:29<00:00, 191.22it/s]\n",
            "100%|██████████| 5701/5701 [00:30<00:00, 187.97it/s]\n",
            "100%|██████████| 5701/5701 [00:26<00:00, 216.32it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.45it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.23it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 309.59it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.71it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 311.91it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.39it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.88it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 305.10it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.20it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 304.53it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.60it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 316.46it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.82it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.66it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 298.50it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.80it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.14it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 306.78it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.61it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 287.36it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 307.67it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 316.75it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.52it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.05it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 316.25it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.30it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 301.33it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 306.32it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 323.55it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 316.29it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.19it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 311.55it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.45it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.12it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.42it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.08it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.82it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.81it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 325.53it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.04it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.32it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.55it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.26it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 325.21it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.15it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.71it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.93it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.07it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.58it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.46it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.43it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.73it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 323.44it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.27it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.19it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.38it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.66it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.91it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.05it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.19it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.45it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.80it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.65it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 323.62it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.16it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.49it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.48it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.27it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.10it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 311.30it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.17it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.49it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 331.98it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.59it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.74it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.35it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.39it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.26it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.31it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.40it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.83it/s]\n",
            "100%|██████████| 5701/5701 [00:16<00:00, 338.89it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 333.03it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.73it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.89it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.13it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 331.29it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.69it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 330.27it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 333.16it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.22it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 330.28it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.91it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.69it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.82it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.14it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.54it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 333.12it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.37it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 328.10it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.24it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.34it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.87it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 333.76it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.84it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.30it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.24it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.02it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.71it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.46it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 334.44it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.69it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.44it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.85it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.16it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 332.48it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 313.55it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.77it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.78it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.26it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.63it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.41it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 305.81it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.62it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.19it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.50it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 323.61it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.51it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 294.19it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.38it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.43it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.74it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.67it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.86it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.57it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.12it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 327.03it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.22it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.92it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.00it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.31it/s]\n",
            "100%|██████████| 5701/5701 [00:16<00:00, 335.41it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.77it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 329.58it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 326.74it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 330.25it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.00it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.19it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.67it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.40it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 322.79it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.41it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 300.59it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 310.94it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.73it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.02it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 302.14it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 303.34it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 299.69it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 309.85it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.64it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 317.77it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.85it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.88it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.03it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 305.96it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 309.52it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 294.96it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 304.02it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 298.10it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 309.53it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.15it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 318.83it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 311.26it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 302.72it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 321.96it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 293.51it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 303.91it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 302.43it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 315.34it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.80it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 308.55it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 312.65it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 314.30it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 301.55it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 320.70it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 324.55it/s]\n",
            "100%|██████████| 5701/5701 [00:18<00:00, 311.30it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.16it/s]\n",
            "100%|██████████| 5701/5701 [00:17<00:00, 319.08it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 296.20it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 295.68it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 292.30it/s]\n",
            "100%|██████████| 5701/5701 [00:19<00:00, 293.02it/s]\n",
            " 57%|█████▋    | 3231/5701 [00:09<00:08, 281.62it/s]"
          ]
        }
      ],
      "source": [
        "# 학습 루프 정의\n",
        "\n",
        "for epoch in range(300):\n",
        "  iterator = tqdm.tqdm(loader(dataset), total = len(dataset))\n",
        "  total_loss = 0\n",
        "\n",
        "  for data, label in iterator:\n",
        "      data = torch.tensor(data, dtype = torch.long).to(device)\n",
        "      label = torch.tensor(label, dtype = torch.long).to(device)\n",
        "\n",
        "      # 인코더의 초기 은닉 상태\n",
        "      encoder_hidden  = torch.zeros(1, 1, 64).to(device)\n",
        "      # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "      encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "\n",
        "      loss = 0\n",
        "\n",
        "      for ei in range(len(data)):\n",
        "          # 한 단어씩 인코더에 넣어줌\n",
        "          encoder_output, encoder_hidden = encoder(\n",
        "            data[ei], encoder_hidden)\n",
        "          # 인코더의 은닉 상태를 저장\n",
        "          encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "      decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "      # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 저장\n",
        "      decoder_hidden = encoder_hidden\n",
        "      # (option 1) 50% 확률로 teacher forcing 사용\n",
        "      # use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "      # (option 2) 강제로 teacher forcing 사용\n",
        "\n",
        "      use_teacher_forcing = True\n",
        "      if use_teacher_forcing:\n",
        "          for di in range(len(label)):    # di인 이유? decoder index? 다른의미?\n",
        "              decoder_output = decoder(\n",
        "                  decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "              # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "              target = torch.tensor(label[di], dtype = torch.long).to(device)\n",
        "              target = target.unsqueeze(0).to(device)\n",
        "              loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "              decoder_input = target\n",
        "      else:\n",
        "          for di in range(len(label)):\n",
        "              # 디코더의 출력 계산\n",
        "              decoder_output = decoder(\n",
        "                  decoder_input, decoder_hidden, encoder_outputs)\n",
        "              # 예측된 단어 중 가장 확률이 높은 top1 단어를 다음 입력으로 사용\n",
        "              topv, topi = decoder_output.topk(1)\n",
        "              decoder_input = topi.squeeze().detach()\n",
        "\n",
        "              # 현재 시점의 정답과 비교하여 손실계산\n",
        "              target = torch.tensor(label[di], dtype = torch.long).to(device)\n",
        "              target = target.unsqueeze(target, dim=0).to(device)\n",
        "              loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "\n",
        "              if decoder_input.item() == 1:         # <EOS> 토큰을 만나면 중지\n",
        "                  break\n",
        "\n",
        "          # 문장 하나에 대한 평균 손실 계산 후 누적\n",
        "          total_loss += loss.item()/len(dataset)\n",
        "          iterator.set_description(f\"Epoch {epoch} loss: {total_loss}\")\n",
        "          loss.backward()\n",
        "\n",
        "          encoder_optimizer.step()\n",
        "          decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pth\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAT82LVW4SMC",
        "outputId": "45e4123c-45cb-49c9-9b81-3f7dc93c60d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\109-1\\AppData\\Local\\Temp\\ipykernel_17824\\3180288879.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  encoder.load_state_dict(torch.load(\"attn_enc.pth\", map_location=device))\n",
            "C:\\Users\\109-1\\AppData\\Local\\Temp\\ipykernel_17824\\3180288879.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder.load_state_dict(torch.load(\"attn_dec.pth\", map_location=device))\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"attention.weight\", \"attention.bias\", \"context.weight\", \"context.bias\", \"out.weight\", \"out.bias\". \n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([3048, 64]) from checkpoint, the shape in current model is torch.Size([7466, 64]).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m encoder.load_state_dict(torch.load(\u001b[33m\"\u001b[39m\u001b[33mattn_enc.pth\u001b[39m\u001b[33m\"\u001b[39m, map_location=device))\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 디코더 가중치 불러오기\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattn_dec.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 불러올 영어 문장을 랜덤하게 지정\u001b[39;00m\n\u001b[32m      9\u001b[39m idx = random.randint(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\109-1\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2576\u001b[39m         error_msgs.insert(\n\u001b[32m   2577\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2578\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2579\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2580\u001b[39m             ),\n\u001b[32m   2581\u001b[39m         )\n\u001b[32m   2583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2586\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2587\u001b[39m         )\n\u001b[32m   2588\u001b[39m     )\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"attention.weight\", \"attention.bias\", \"context.weight\", \"context.bias\", \"out.weight\", \"out.bias\". \n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([3048, 64]) from checkpoint, the shape in current model is torch.Size([7466, 64])."
          ]
        }
      ],
      "source": [
        "# 모델 성능 평가에 필요한 요소 정의\n",
        "\n",
        "# 인코더 가중치 불러오고\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pth\", map_location=device))\n",
        "# 디코더 가중치 불러오기\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pth\", map_location=device))\n",
        "\n",
        "# 불러올 영어 문장을 랜덤하게 지정\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\"\n",
        "\n",
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype = torch.long).to(device)\n",
        "label = torch.tensor(label, dtype = torch.long).to(device)\n",
        "\n",
        "# 인코더의 초기 은닉 상태 정의\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "# 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmtP2sRy4iil"
      },
      "outputs": [],
      "source": [
        "# 인코더 동작\n",
        "\n",
        "for ei in range(len(data)):\n",
        "  # 한 단어씩 인코더에 넣어줌\n",
        "  encoder_output, encoder_hidden = encoder(data[ei], encoder_hidden)\n",
        "\n",
        "  # 인코더의 출력을 저장\n",
        "  encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "# 디코더의 초기 입력\n",
        "# 0은 <SOS>  토큰\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "# 디코더의 초기 은닉 상태는 인코더의 마지막 hidden state로 설정\n",
        "decoder_hidden = encoder_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvI7fjew41j0"
      },
      "outputs": [],
      "source": [
        "# 디코더 동작\n",
        "\n",
        "for di in range(11): # 최대 11단어까지 예측 (길이 제한)\n",
        "    # 현재 입력, hidden state, 인코더 출력을 기반으로 다음 단어 예측\n",
        "    decoder_output = decoder(\n",
        "        decoder_input, decoder_hidden, encoder_outputs)\n",
        "    # 예측 단어 중 가장 확률이 높은 단어 선택\n",
        "    topv, topi = decoder_output.topk(1) # topi: 예측된 단어 인덱스\n",
        "    decoder_input = topi.squeeze().detach() # 다음 입력으로 설정 (detach로 gradient 제외)\n",
        "\n",
        "    # <EOS> 토큰을 만나면 중지\n",
        "    if decoder_input.item() == 1:\n",
        "      break\n",
        "\n",
        "    # 가장 높은 확률값의 단어를 문자열에 추가\n",
        "    pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n",
        "\n",
        "print(input_sentence)   # 영어 문장\n",
        "print(pred_sentence)    # 번역한 한글 문장"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}